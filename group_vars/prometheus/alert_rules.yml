prometheus_alert_rules:
  - alert: Watchdog
    expr: vector(1)
    for: 10m
    labels:
      severity: warning
    annotations:
      description: 'This is an alert meant to ensure that the entire alerting pipeline is functional.
        This alert is always firing, therefore it should always be firing in Alertmanager
        and always fire against a receiver. There are integrations with various notification
        mechanisms that send a notification when this alert is not firing. For example the
        "DeadMansSnitch" integration in PagerDuty.'
      summary: 'Ensure entire alerting pipeline is functional'
      
  - alert: InstanceDown
    expr: "up == 0"
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} down{% endraw %}"

  - alert: CriticalCPULoad
    expr: '100 - (avg by (instance) (irate(node_cpu_seconds_total{job="node",mode="idle"}[5m])) * 100) > 96'
    for: 2m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has Critical CPU load for more than 2 minutes.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - Critical CPU load{% endraw %}"

  - alert: CriticalRAMUsage
    expr: '(1 - ((node_memory_MemFree_bytes + node_memory_Buffers_bytes + node_memory_Cached_bytes) / node_memory_MemTotal_bytes)) * 100 > 98'
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} has Critical Memory Usage more than 5 minutes.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} has Critical Memory Usage{% endraw %}"

  - alert: CriticalDiskSpace
    expr: 'node_filesystem_free_bytes{mountpoint!~"^/run(/.*|$)",fstype!~"(squashfs|fuse.*)",job="node"} / node_filesystem_size_bytes{job="node"} < 0.1'
    for: 4m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}{{ $labels.instance }} of job {{ $labels.job }} has less than 10% space remaining.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - Critical disk space usage{% endraw %}"

  - alert: RebootRequired
    expr: "node_reboot_required > 0"
    labels:
      severity: warning
    annotations:
      description: "{% raw %}{{ $labels.instance }} requires a reboot.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - reboot required{% endraw %}"

  - alert: ClockSkewDetected
    expr: 'abs(node_timex_offset_seconds) * 1000 > 30'
    for: 2m
    labels:
      severity: warning
    annotations:
      description: "{% raw %}Clock skew detected on {{ $labels.instance }}. Ensure NTP is configured correctly on this host.{% endraw %}"
      summary: "{% raw %}Instance {{ $labels.instance }} - Clock skew detected{% endraw %}"

#  - alert: BigLatency
#    expr: "probe_duration_seconds{job='icmp'} > 1"
#    for: 5m
#    labels:
#      severity: warning
#    annotations:
#      description: "{% raw %}Ping to {{ $labels.instance }} is slower than 1 sec{% endraw %}"
#      summary: "{% raw %}Instance {{ $labels.instance }} - big latency{% endraw %}"

  - alert: HighTemperature
    expr: 'netdata_sensors_temperature_Celsius_average > 65'
    for: 5m
    labels:
      severity: critical
    annotations:
      description: "{% raw %}Temperature on {{ $labels.instance }} is higher than 64 Celsius degree.{% endraw %}"
      summary: "{% raw %}Temperature on {{ $labels.instance }} is higher than 64 Celsius degree.{% endraw %}"

  - alert: SslCertificateWillExpireSoon
    expr: 'probe_ssl_earliest_cert_expiry - time() < 86400 * 30'
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}SSL certificate will expire soon (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}SSL certificate expires in 30 days\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"

  - alert: SslCertificateHasExpired
    expr: 'probe_ssl_earliest_cert_expiry - time()  <= 0'
    for: 5m
    labels:
      severity: error
    annotations:
      summary: "{% raw %}SSL certificate has expired (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}SSL certificate has expired already\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"

  - alert: BlackboxSlowRequests
    expr: 'probe_http_duration_seconds > 2'
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Blackbox slow requests (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Blackbox request took more than 2s\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"

  - alert: BlackboxSlowPing
    expr: 'probe_icmp_duration_seconds > 2'
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "{% raw %}Blackbox slow ping (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}Blackbox ping took more than 2s\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"

  - alert: StatusCode
    expr: 'probe_http_status_code <= 199 OR probe_http_status_code >= 400'
    for: 5m
    labels:
      severity: error
    annotations:
      summary: "{% raw %}Status Code (instance {{ $labels.instance }}){% endraw %}"
      description: "{% raw %}HTTP status code is not 200-399\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"

  - alert: StatusCode
    expr: 'rate(mikrotik_interface_rx_error[4m]) > 0 OR rate(mikrotik_interface_tx_error[4m]) > 0'
    labels:
      severity: error
    annotations:
      summary: "{% raw %}Interface errors are increase (instance {{ $labels.name }}, interface {{ $labels.interface }}){% endraw %}"
      description: "{% raw %}Erroors on interface\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}{% endraw %}"
      
      